{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab37ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi\")\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 87620 entries, 0 to 87619\n",
      "Series name: pickup_hour\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "87620 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 684.7 KB\n",
      "Train set size: (55900, 674)\n",
      "Test set size: (31720, 674)\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=   6.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=   6.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=   5.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=   4.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=   5.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=   5.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=   5.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=   4.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=   4.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=   4.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=   3.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=   4.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 159913\n",
      "[LightGBM] [Info] Number of data points in the train set: 55900, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.110286\n",
      "No FFT - Step 1 - Best LR: 0.1\n",
      "No FFT - Step 1 - CV MAE: 2.580\n",
      "No FFT - Step 1 - Test MAE: 3.220\n",
      "üèÉ View run No FFT - Step 1 at: http://127.0.0.1:5000/#/experiments/126531033133523133/runs/62fc72c22d74469f865669d204ded7d8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126531033133523133\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=   6.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=   4.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  16.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  15.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  15.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   6.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   8.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=   7.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=   9.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=  10.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=   9.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=   3.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=   8.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=   7.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   7.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   7.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   6.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   6.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   6.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=   7.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156723\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  13.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153420\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  15.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 155219\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  14.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 159913\n",
      "[LightGBM] [Info] Number of data points in the train set: 55900, number of used features: 674\n",
      "[LightGBM] [Info] Start training from score 11.110286\n",
      "No FFT - Best Params Step 2: {'lgbmregressor__subsample': 0.7, 'lgbmregressor__num_leaves': 31, 'lgbmregressor__min_child_samples': 10, 'lgbmregressor__colsample_bytree': 0.7}\n",
      "No FFT - CV MAE Step 2: 2.516\n",
      "No FFT - Test MAE Step 2: 3.241\n",
      "üèÉ View run No FFT - Step 2 at: http://127.0.0.1:5000/#/experiments/126531033133523133/runs/689b40d563be4bb58de7ffd43b1c4ce0\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126531033133523133\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=  17.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=  16.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.01; total time=  17.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=  15.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=  16.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ..................lgbmregressor__learning_rate=0.05; total time=  14.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=  16.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=  15.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.1; total time=  17.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=  15.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=  17.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.2; total time=  15.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=  17.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=  14.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END ...................lgbmregressor__learning_rate=0.3; total time=  17.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161188\n",
      "[LightGBM] [Info] Number of data points in the train set: 55900, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.110286\n",
      "With FFT - Step 1 - Best LR: 0.1\n",
      "With FFT - Step 1 - CV MAE: 2.553\n",
      "With FFT - Step 1 - Test MAE: 3.211\n",
      "üèÉ View run With FFT - Step 1 at: http://127.0.0.1:5000/#/experiments/126531033133523133/runs/3fcee519343644cba5c02b420a80f79a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126531033133523133\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=  15.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=  17.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.8; total time=  15.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  26.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  25.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.7; total time=  23.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  16.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  17.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=20, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  15.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  16.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  15.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=50, lgbmregressor__subsample=0.7; total time=  16.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=  21.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=  19.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=1.0, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.8; total time=  21.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=  23.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=  16.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=31, lgbmregressor__subsample=0.7; total time=  29.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=  26.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=  21.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.7, lgbmregressor__min_child_samples=10, lgbmregressor__num_leaves=100, lgbmregressor__subsample=0.7; total time=  19.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  19.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  20.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=5, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  18.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  19.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  19.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=70, lgbmregressor__subsample=1.0; total time=  18.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 157998\n",
      "[LightGBM] [Info] Number of data points in the train set: 37266, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 13.482799\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  33.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 154695\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 8.169855\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  30.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 156494\n",
      "[LightGBM] [Info] Number of data points in the train set: 37267, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.678268\n",
      "[CV] END lgbmregressor__colsample_bytree=0.8, lgbmregressor__min_child_samples=40, lgbmregressor__num_leaves=256, lgbmregressor__subsample=0.8; total time=  27.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161188\n",
      "[LightGBM] [Info] Number of data points in the train set: 55900, number of used features: 679\n",
      "[LightGBM] [Info] Start training from score 11.110286\n",
      "With FFT - Best Params Step 2: {'lgbmregressor__subsample': 0.8, 'lgbmregressor__num_leaves': 256, 'lgbmregressor__min_child_samples': 40, 'lgbmregressor__colsample_bytree': 0.8}\n",
      "With FFT - CV MAE Step 2: 2.506\n",
      "With FFT - Test MAE Step 2: 3.216\n",
      "üèÉ View run With FFT - Step 2 at: http://127.0.0.1:5000/#/experiments/126531033133523133/runs/a7ed456a17eb44769765f7cb0a341e5d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126531033133523133\n",
      "\n",
      "================== FINAL COMPARISON ==================\n",
      "No FFT Final MAE:  3.241\n",
      "FFT Final MAE:     3.216\n",
      "FFT features improved the performance!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "from src.pipeline_utils import (\n",
    "    average_rides_last_4_weeks,\n",
    "    TemporalFeatureEngineer,\n",
    "    FFTFeatureEngineer\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# === Your custom imports ===\n",
    "from src.data_utils import split_time_series_data\n",
    "from src.config import TRANSFORMED_DATA_DIR\n",
    "\n",
    "# ---- 1) Load Data ----\n",
    "df = pd.read_parquet(TRANSFORMED_DATA_DIR / \"tabular_data.parquet\")\n",
    "df[\"pickup_hour\"].info()\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_time_series_data(\n",
    "    df, cutoff_date=datetime(2023, 9, 1, 0, 0, 0), target_column=\"target\"\n",
    ")\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "\n",
    "\n",
    "# ---- Create two pipelines: no FFT vs. FFT ----\n",
    "# Pipeline A: No FFT (baseline)\n",
    "baseline_pipeline = make_pipeline(\n",
    "    add_feature_average_rides_last_4_weeks,\n",
    "    add_temporal_features,\n",
    "    lgb.LGBMRegressor()  # default LGBM\n",
    ")\n",
    "\n",
    "# Pipeline B: With FFT\n",
    "fft_pipeline = make_pipeline(\n",
    "    add_feature_average_rides_last_4_weeks,\n",
    "    add_temporal_features,\n",
    "    FFTFeatureEngineer(window_size=24, top_k=5, drop_original=False),\n",
    "    lgb.LGBMRegressor()\n",
    ")\n",
    "\n",
    "# 3) Set MLflow experiment\n",
    "mlflow.set_experiment(\"FFT_Comparison_Experiment\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# HELPER FUNCTION: 2-step tuning for any pipeline\n",
    "# ------------------------------------------------------------------------\n",
    "def two_step_tuning(pipeline, run_name_prefix=\"No FFT\"):\n",
    "    # Step 1: Learning rate only\n",
    "    step1_param_grid = {\n",
    "        \"lgbmregressor__learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{run_name_prefix} - Step 1\"):\n",
    "        gridsearch = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=step1_param_grid,\n",
    "            scoring=\"neg_mean_absolute_error\",\n",
    "            cv=3,\n",
    "            verbose=2\n",
    "        )\n",
    "        gridsearch.fit(X_train, y_train)\n",
    "        best_lr = gridsearch.best_params_[\"lgbmregressor__learning_rate\"]\n",
    "        cv_mae_step1 = -gridsearch.best_score_\n",
    "\n",
    "        mlflow.log_param(\"best_learning_rate\", best_lr)\n",
    "        mlflow.log_metric(\"cv_mae_step1\", cv_mae_step1)\n",
    "        \n",
    "        # Evaluate on test\n",
    "        step1_best_model = gridsearch.best_estimator_\n",
    "        y_pred_step1 = step1_best_model.predict(X_test)\n",
    "        test_mae_step1 = mean_absolute_error(y_test, y_pred_step1)\n",
    "        mlflow.log_metric(\"test_mae_step1\", test_mae_step1)\n",
    "\n",
    "        print(f\"{run_name_prefix} - Step 1 - Best LR: {best_lr}\")\n",
    "        print(f\"{run_name_prefix} - Step 1 - CV MAE: {cv_mae_step1:.3f}\")\n",
    "        print(f\"{run_name_prefix} - Step 1 - Test MAE: {test_mae_step1:.3f}\")\n",
    "\n",
    "    # Step 2: Fix best LR, tune other hyperparams\n",
    "    # We clone the pipeline with the best LR\n",
    "    from sklearn.base import clone\n",
    "    tuned_pipeline = clone(pipeline)\n",
    "    tuned_pipeline[-1].set_params(learning_rate=best_lr) \n",
    "    # the LGBMRegressor is the last step in the pipeline\n",
    "\n",
    "    step2_param_dist = {\n",
    "        \"lgbmregressor__num_leaves\": [31, 50, 70, 100, 256],\n",
    "        \"lgbmregressor__min_child_samples\": [5, 10, 20, 40],\n",
    "        \"lgbmregressor__subsample\": [0.7, 0.8, 1.0],\n",
    "        \"lgbmregressor__colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{run_name_prefix} - Step 2\"):\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=tuned_pipeline,\n",
    "            param_distributions=step2_param_dist,\n",
    "            n_iter=10,\n",
    "            scoring=\"neg_mean_absolute_error\",\n",
    "            cv=3,\n",
    "            verbose=2,\n",
    "            random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = random_search.best_params_\n",
    "        cv_mae_step2 = -random_search.best_score_\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"cv_mae_step2\", cv_mae_step2)\n",
    "\n",
    "        final_best_model = random_search.best_estimator_\n",
    "        y_pred_step2 = final_best_model.predict(X_test)\n",
    "        test_mae_step2 = mean_absolute_error(y_test, y_pred_step2)\n",
    "        mlflow.log_metric(\"test_mae_step2\", test_mae_step2)\n",
    "\n",
    "        print(f\"{run_name_prefix} - Best Params Step 2: {best_params}\")\n",
    "        print(f\"{run_name_prefix} - CV MAE Step 2: {cv_mae_step2:.3f}\")\n",
    "        print(f\"{run_name_prefix} - Test MAE Step 2: {test_mae_step2:.3f}\")\n",
    "\n",
    "    return final_best_model, test_mae_step2\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4) Baseline Pipeline (No FFT)\n",
    "# ------------------------------------------------------------------------\n",
    "baseline_model, baseline_final_mae = two_step_tuning(\n",
    "    pipeline=baseline_pipeline, run_name_prefix=\"No FFT\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5) FFT Pipeline\n",
    "# ------------------------------------------------------------------------\n",
    "fft_model, fft_final_mae = two_step_tuning(\n",
    "    pipeline=fft_pipeline, run_name_prefix=\"With FFT\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6) Compare Results\n",
    "# ------------------------------------------------------------------------\n",
    "print(\"\\n================== FINAL COMPARISON ==================\")\n",
    "print(f\"No FFT Final MAE:  {baseline_final_mae:.3f}\")\n",
    "print(f\"FFT Final MAE:     {fft_final_mae:.3f}\")\n",
    "\n",
    "if fft_final_mae < baseline_final_mae:\n",
    "    print(\"FFT features improved the performance!\")\n",
    "else:\n",
    "    print(\"FFT features did not help, or at least not in this config.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a0e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472792d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd939536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a80521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-03 00:03:23,481 INFO: Initializing external client\n",
      "2025-03-03 00:03:23,482 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-03 00:03:24,342 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214632\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME, api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "feature_store = project.get_feature_store()\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc4a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view 'time_series_hourly_feature_view' (version 1) retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a feature view if it doesn't already exist\n",
    "# try:\n",
    "#     feature_store.create_feature_view(\n",
    "#         name=config.FEATURE_VIEW_NAME,\n",
    "#         version=config.FEATURE_VIEW_VERSION,\n",
    "#         query=feature_group.select_all(),\n",
    "#     )\n",
    "#     print(f\"Feature view '{config.FEATURE_VIEW_NAME}' (version {config.FEATURE_VIEW_VERSION}) created successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "# Retrieve the feature view\n",
    "try:\n",
    "    feature_view = feature_store.get_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "    )\n",
    "    print(f\"Feature view '{config.FEATURE_VIEW_NAME}' (version {config.FEATURE_VIEW_VERSION}) retrieved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving feature view: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ad628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (7.73s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `5`.\n"
     ]
    }
   ],
   "source": [
    "ts_data, _ = feature_view.training_data(\n",
    "    description=\"Time-series hourly taxi rides\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cd67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.sort_values([\"pickup_location_id\", \"pickup_hour\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a049fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.head()\n",
    "ts_data_copy = ts_data.copy()\n",
    "import pandas as pd\n",
    "ts_data[\"pickup_hour\"] = pd.to_datetime(ts_data[\"pickup_hour\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a187c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)  # Remove timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0c832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"year_month\"] = ts_data[\"pickup_hour\"].dt.to_period(\"M\")  # Year-Month format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aee52b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by year_month and count\n",
    "hour_counts = ts_data.groupby(\"year_month\").size()\n",
    "\n",
    "# Plot the data\n",
    "ax = hour_counts.plot(kind=\"bar\", figsize=(10, 6), color=\"skyblue\", edgecolor=\"black\")  # Use 'ax' to store the plot object\n",
    "ax.set_title(\"Number of Hours by Year/Month\", fontsize=16)\n",
    "ax.set_xlabel(\"Year-Month\", fontsize=12)\n",
    "ax.set_ylabel(\"Count of Hours\", fontsize=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b96cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31e60fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour  pickup_location_id  rides year_month\n",
       "0 2023-01-01 00:00:00                   2      0    2023-01\n",
       "1 2023-01-01 01:00:00                   2      0    2023-01\n",
       "2 2023-01-01 02:00:00                   2      0    2023-01\n",
       "3 2023-01-01 03:00:00                   2      0    2023-01\n",
       "4 2023-01-01 04:00:00                   2      0    2023-01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.head()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fcfe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gte = ts_data[\"year_month\"] >= pd.Period(\"2023-01\", freq=\"M\")\n",
    "lte = ts_data[\"year_month\"] <= pd.Period(\"2023-12\", freq=\"M\")\n",
    "cond = gte & lte\n",
    "filtered_data = ts_data[cond].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b0e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.drop(columns=[\"year_month\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be15868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277600, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1987f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_ts_data_info_features_and_target\n",
    "\n",
    "features, targets = transform_ts_data_info_features_and_target(ts_data, window_size=24*28, step_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23b04f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91520, 675)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_targets = features.copy()\n",
    "features_targets[\"target\"] = targets\n",
    "\n",
    "features_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81509b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# For example, assume 'features' is a pandas DataFrame \n",
    "# used as input and 'targets' is a pandas Series or DataFrame for outputs.\n",
    "\n",
    "input_schema = Schema(features)\n",
    "output_schema = Schema(targets)\n",
    "\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema,\n",
    "    output_schema=output_schema\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d974582d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/src/lgb_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  # or pickle\n",
    "# Suppose your final best model is called 'best_model'\n",
    "joblib.dump(fft_model, \"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/models/lgb_model.pkl\")\n",
    "\n",
    "\n",
    "import joblib  # or pickle\n",
    "# Suppose your final best model is called 'best_model'\n",
    "joblib.dump(fft_model, \"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/src/lgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc3fe3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.215850550588589"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_final_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e93e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8844d10527fb43f98196a0d8ef0e1a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2741eb3955354afc817904cb2dd74c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/2299859 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea21a6b223c840c2a946599f83d06505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/3166 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eff5ffaa6be4f52932bf8fa206a3443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/48616 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1214632/models/taxi_demand_predictor_next_hour/4\n",
      "Model successfully saved to Hopsworks Model Registry!\n"
     ]
    }
   ],
   "source": [
    "# Retrieve your project's Model Registry\n",
    "model_registry = project.get_model_registry()\n",
    "\n",
    "# Create the model entry in the registry\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"taxi_demand_predictor_next_hour\",\n",
    "    metrics={\"test_mae\": fft_final_mae},\n",
    "    description=\"LightGBM regressor tuned\",\n",
    "    input_example=features.sample(),   # an example row of inputs\n",
    "    model_schema=model_schema,\n",
    "    # include_files=[\"src/\", \"requirements.txt\"]  # optional if you have source code to bundle\n",
    ")\n",
    "\n",
    "# Save the model artifacts (pickle, etc.) to Hopsworks\n",
    "# Typically you provide a local path to the model file\n",
    "model.save(\"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/models/lgb_model.pkl\")\n",
    "\n",
    "# lgb_model.pkl\n",
    "\n",
    "print(\"Model successfully saved to Hopsworks Model Registry!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76652a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi\")\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ashtik/ub_cse_cda_500/cda_500_nyc_taxi/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f1fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline_utils import (\n",
    "    TemporalFeatureEngineer,\n",
    "    average_rides_last_4_weeks,  # Make sure this is correctly imported\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e29a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-03 00:12:22,493 INFO: Initializing external client\n",
      "2025-03-03 00:12:22,494 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-03 00:12:23,303 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214632\n",
      "<function average_rides_last_4_weeks at 0x7f13a56f45e0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'FFTFeatureEngineer' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model_from_registry\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Suppose you have a function get_model_predictions that \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# wraps the pipeline's predict method:\u001b[39;00m\n",
      "File \u001b[0;32m~/ub_cse_cda_500/cda_500_nyc_taxi/src/inference.py:91\u001b[0m, in \u001b[0;36mload_model_from_registry\u001b[0;34m(version)\u001b[0m\n\u001b[1;32m     87\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(average_rides_last_4_weeks)  \u001b[38;5;66;03m# This should not raise an error\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlgb_model.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/ub_cse_cda_500/cda_500_nyc_taxi/.venv/lib/python3.10/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/ub_cse_cda_500/cda_500_nyc_taxi/.venv/lib/python3.10/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/usr/lib/python3.10/pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pickle.py:1582\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m-> 1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, subpath)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m                              \u001b[38;5;241m.\u001b[39mformat(name, obj)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, parent\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'FFTFeatureEngineer' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "from src.inference import load_model_from_registry\n",
    "\n",
    "model = load_model_from_registry()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# Suppose you have a function get_model_predictions that \n",
    "# wraps the pipeline's predict method:\n",
    "from src.inference import get_model_predictions\n",
    "\n",
    "predictions_df = get_model_predictions(model, features)  \n",
    "# 'predictions_df' might be a DataFrame with a \"predicted_demand\" column\n",
    "\n",
    "test_mae_loaded = mean_absolute_error(targets, predictions_df[\"predicted_demand\"])\n",
    "print(f\"MAE of model loaded from Hopsworks: {test_mae_loaded:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81c657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be11922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
